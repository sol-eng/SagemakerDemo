---
title: "Sagemaker Demo"
author: "Gagandeep Singh"
date: '2023-06-02'
output: html_document
---

```{r setup, include=FALSE}

# set repo to bionic
getOption("repos")
options(repos = c(REPO_NAME = "https://packagemanager.posit.co/cran/__linux__/bionic/latest"))

library(tidyverse)
library(tidymodels)
library(reticulate)
library(DT)
library(knitr)
library(aws.s3)
library(pROC)
library(glue)
library(vetiver)
library(pins)
library(paws)
# to get access credentials
library(aws.ec2metadata)

knitr::opts_chunk$set(echo = TRUE)

```

## Input data for analysis


```{r input_data}

churn <- read_csv(file = "dataset/churn.txt", col_names = TRUE, show_col_types = FALSE)

kable(churn[1:10,], caption = "Customer churn in a cellular company")

```

## Exploring data


```{r data_eda}


churn = select(churn, -c("Phone", "Day Charge", "Eve Charge", "Night Charge", "Intl Charge"))

churn <- rename(churn, "intlplan" = "Int'l Plan")
churn <- rename(churn, "churn" = "Churn?")


ggplot(churn, aes(x = churn, fill = intlplan)) +  geom_bar() + theme_classic()

```

```{r data_eda_2}

hist(churn$"CustServ Calls"[which(churn$churn == "True.")], col = 'red', breaks = 15, ylim = c(0,600), main = "Churn = True", xlab = "Customer Service Calls")


```

```{r data_eda_3}

hist(churn$"CustServ Calls"[which(churn$churn == "False.")], col = 'blue', breaks = 15, ylim = c(0,600), main = "Churn = False", xlab = "Customer Service Calls")


```

```{r data_eda_4}

#Changing target variable churn into dummy variable and keeping just True column while dropping False
churn <- churn %>% mutate(dummy=1) %>% spread(key="churn",value=dummy, fill=0)
churn <- subset(churn, select = -c(False.))
churn <- rename(churn, "churn" = True.)

#Making the target variable "churn" as the first column as XGBoost expects the data to be in this format
churn <- churn %>% select("churn", everything())

#Transforming intlplan (international plan) to dummy, dropping resulting "no" variable and renaming "yes" using dplyr's rename method
churn <- churn %>% mutate(dummy=1) %>% spread(key="intlplan",value=dummy, fill=0)
churn <- subset(churn, select = -c(no))
churn <- rename(churn, "intlplan" = yes)

#Transforming VMaill plan to dummy, dropping resulting "no" variable and renaming "yes" using dplyr's rename method
churn <- churn %>% mutate(dummy=1) %>% spread(key="VMail Plan",value=dummy, fill=0)
churn <- subset(churn, select = -c(no))
churn <- rename(churn, "VMail plan" = yes)

#Transforming variable "State" into dummy variables
churn <- churn %>% mutate(dummy=1) %>% spread(key="State",value=dummy, fill=0)
head(churn)

```


```{r data_test_train_split}

churn_train <- churn %>% sample_frac(size = 0.7)
churn <- anti_join(churn, churn_train)

churn_test <- churn %>% sample_frac(size = 0.5)
churn_valid <- anti_join(churn, churn_test)

write_csv(churn_train, 'dataset/churn_train.csv', col_names = FALSE)
write_csv(churn_valid, 'dataset/churn_valid.csv', col_names = FALSE)
# Remove target from test
write_csv(churn_test[-1], 'dataset/churn_test.csv', col_names = FALSE)


```

## Working with Sagemker Python SDK

```{r sagemaker_setup}

library(reticulate)
sagemaker <- import('sagemaker')
session <- sagemaker$Session()
bucket <- session$default_bucket()
role_arn <- sagemaker$get_execution_role()
#print(role_arn)
#print(bucket)

```


```{r data_upload_s3}

s3_train <- session$upload_data(path = 'dataset/churn_train.csv', bucket = bucket, key_prefix = 'r_example/data')
s3_valid <- session$upload_data(path = 'dataset/churn_valid.csv', bucket = bucket, key_prefix = 'r_example/data')
s3_test <- session$upload_data(path = 'dataset/churn_test.csv',   bucket = bucket, key_prefix = 'r_example/data')

```


```{r data_download_s3}

# create paws s3 object
s3 <- paws::s3()

s3_download <- s3$get_object(
  Bucket = bucket,
  Key = 'r_example/data/churn_train.csv'
)

require(magrittr)
s3_download$Body %>% rawToChar %>% read.csv(text = .)


```



## Sagemaker Modelling

Specifying the training and validation data channels for model training

```{r}

s3_train_input <- sagemaker$inputs$TrainingInput(s3_data = s3_train, content_type = 'csv')
s3_valid_input <- sagemaker$inputs$TrainingInput(s3_data = s3_valid, content_type = 'csv')
input_data <- list('train' = s3_train_input, 'validation' = s3_valid_input)

```

Using Sagemaker's builtin XGBoost model container for model training

```{r}

container <- sagemaker$image_uris$retrieve(framework='xgboost', region= session$boto_region_name, version='latest')
cat('XGBoost Container Image URL: ', container)
s3_output <- paste0('s3://', bucket, '/r_example/output')


estimator <- sagemaker$estimator$Estimator(image_uri = container,
                                           role = role_arn,
                                           instance_count = 1L,
                                           instance_type = 'ml.m5.xlarge',
                                           input_mode = 'File',
                                           output_path = s3_output)

estimator$set_hyperparameters(eval_metric='error',
                              objective='binary:logistic',
                              num_round=100L)


```

Starting the model training job

```{r echo=FALSE}

estimator$fit(inputs = input_data, wait=TRUE, logs=TRUE)

```

Deploying our trained model as a Sagemaker endpoint 

```{r}

model_endpoint <- estimator$deploy(initial_instance_count=1L, instance_type='ml.m4.xlarge')
model_endpoint$serializer <- sagemaker$serializers$CSVSerializer(content_type='text/csv')

```

making predictions

```{r}

test_sample <- as.matrix(churn_test[-1])
dimnames(test_sample)[[2]] <- NULL
predictions_ep <- model_endpoint$predict(test_sample)
predictions_ep <- as.character(predictions_ep)
predictions_ep <- str_split(predictions_ep, pattern = ',', simplify = TRUE)
predictions_ep <- as.numeric(unlist(predictions_ep))
churn_predictions_ep <- cbind(predicted_churn = predictions_ep, churn_test)
head(churn_predictions_ep)

```

Plotting the ROC curve

```{r}

roc_churn <- roc(churn_predictions_ep$churn, churn_predictions_ep$predicted_churn)
auc_churn <- roc_churn$auc
# Creating ROC plot
ggroc(roc_churn, colour = 'red', size = 1.3) + ggtitle(paste0('Receiver Operating Characteristics (ROC) Curve ', '(AUC = ', round(auc_churn, digits = 3), ')'))

```

Delete the endpoint when done

```{r}

model_endpoint$delete_endpoint(delete_endpoint_config=TRUE)

```

## Vetiver based workflow

```{r test_lm}

model_lm <-
    workflow(churn ~ ., linear_reg()) %>%
    fit(churn_train)


model_lm

```

```{r vetiver_create}

v <- vetiver_model(model_lm, "lm-model")
v
## manually add paws.storage for now
v$metadata$required_pkgs <- c(v$metadata$required_pkgs, "paws.storage")

```

## Publish and version model on AWS S3

```{r vetiver_pin}

model_board <- board_s3(bucket = bucket)
vetiver_pin_write(model_board, v)

```


```{r vetiver_deploy_sagemaker}
endpoint <- vetiver_deploy_sagemaker(
    board = model_board,
    name = "lm-model",
    instance_type = "ml.t2.medium",
    predict_args = list(type = "class", debug = TRUE)
)

```


